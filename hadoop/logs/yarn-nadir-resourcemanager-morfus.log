2015-07-29 10:14:37,481 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = morfus/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-07-29 10:14:37,515 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-29 10:14:39,625 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/usr/local/hadoop/etc/hadoop/core-site.xml
2015-07-29 10:14:40,843 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-29 10:14:41,218 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2015-07-29 10:14:42,305 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/usr/local/hadoop/etc/hadoop/yarn-site.xml
2015-07-29 10:14:44,625 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2015-07-29 10:14:45,178 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2015-07-29 10:14:45,226 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2015-07-29 10:14:45,292 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2015-07-29 10:14:45,813 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2015-07-29 10:14:45,867 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2015-07-29 10:14:45,867 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2015-07-29 10:14:46,076 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2015-07-29 10:14:46,099 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2015-07-29 10:14:46,101 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2015-07-29 10:14:46,117 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2015-07-29 10:14:46,512 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-29 10:14:46,883 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-29 10:14:46,883 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2015-07-29 10:14:46,978 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2015-07-29 10:14:47,037 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2015-07-29 10:14:47,041 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2015-07-29 10:14:47,053 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2015-07-29 10:14:47,057 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2015-07-29 10:14:47,059 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2015-07-29 10:14:47,092 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml
2015-07-29 10:14:47,563 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2015-07-29 10:14:47,563 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2015-07-29 10:14:47,606 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=SUBMIT_APP:*ADMINISTER_QUEUE:*, labels=*,
, reservationsContinueLooking=true
2015-07-29 10:14:47,606 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2015-07-29 10:14:47,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2015-07-29 10:14:47,731 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2015-07-29 10:14:47,748 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = SUBMIT_APP:*ADMINISTER_QUEUE:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2015-07-29 10:14:47,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2015-07-29 10:14:47,749 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2015-07-29 10:14:47,752 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2015-07-29 10:14:47,752 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2015-07-29 10:14:47,762 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2015-07-29 10:14:47,813 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2015-07-29 10:14:47,933 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2015-07-29 10:14:47,946 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2015-07-29 10:14:47,946 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2015-07-29 10:14:47,947 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2015-07-29 10:14:47,948 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2015-07-29 10:14:47,948 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2015-07-29 10:14:47,962 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2015-07-29 10:14:47,977 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2015-07-29 10:14:47,980 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2015-07-29 10:14:47,988 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2015-07-29 10:14:47,989 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2015-07-29 10:14:48,250 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-07-29 10:14:48,356 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2015-07-29 10:14:48,515 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2015-07-29 10:14:48,526 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-29 10:14:48,534 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2015-07-29 10:14:48,842 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-07-29 10:14:48,889 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2015-07-29 10:14:49,175 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2015-07-29 10:14:49,186 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-29 10:14:49,217 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2015-07-29 10:14:49,782 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-07-29 10:14:49,794 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2015-07-29 10:14:49,821 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2015-07-29 10:14:49,823 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-29 10:14:49,873 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2015-07-29 10:14:50,024 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2015-07-29 10:14:50,915 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-29 10:14:51,026 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2015-07-29 10:14:51,110 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2015-07-29 10:14:51,210 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-07-29 10:14:51,230 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2015-07-29 10:14:51,230 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2015-07-29 10:14:51,230 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2015-07-29 10:14:51,232 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2015-07-29 10:14:51,238 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-29 10:14:51,238 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-29 10:14:51,266 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2015-07-29 10:14:51,267 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2015-07-29 10:14:51,372 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2015-07-29 10:14:51,372 INFO org.mortbay.log: jetty-6.1.26
2015-07-29 10:14:51,516 INFO org.mortbay.log: Extract jar:file:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2015-07-29 10:14:52,977 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2015-07-29 10:14:52,995 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2015-07-29 10:14:53,001 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2015-07-29 10:14:53,090 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2015-07-29 10:14:53,090 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /cluster started at 8088
2015-07-29 10:14:56,154 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-07-29 10:14:56,574 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-07-29 10:14:56,583 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2015-07-29 10:14:56,603 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2015-07-29 10:14:56,610 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-29 10:14:56,611 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2015-07-29 10:14:57,089 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved morfus to /default-rack
2015-07-29 10:14:57,103 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: morfus:60035 Node Transitioned from NEW to RUNNING
2015-07-29 10:14:57,107 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node morfus(cmPort: 60035 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId morfus:60035
2015-07-29 10:14:57,162 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node morfus:60035 clusterResource: <memory:8192, vCores:8>
2015-07-29 10:24:47,093 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
2015-07-29 10:40:45,030 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 1
2015-07-29 10:40:47,099 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1438157687835_0001
2015-07-29 10:40:47,110 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 1 submitted by user nadir
2015-07-29 10:40:47,114 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1438157687835_0001
2015-07-29 10:40:47,141 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1438157687835_0001
2015-07-29 10:40:47,141 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0001 State change from NEW to NEW_SAVING
2015-07-29 10:40:47,143 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0001 State change from NEW_SAVING to SUBMITTED
2015-07-29 10:40:47,146 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1438157687835_0001 user: nadir leaf-queue of parent: root #applications: 1
2015-07-29 10:40:47,147 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1438157687835_0001 from user: nadir, in queue: default
2015-07-29 10:40:47,170 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0001 State change from SUBMITTED to ACCEPTED
2015-07-29 10:40:47,244 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1438157687835_0001_000001
2015-07-29 10:40:47,247 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from NEW to SUBMITTED
2015-07-29 10:40:47,295 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 10:40:47,299 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 10:40:47,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1438157687835_0001 from user: nadir activated in queue: default
2015-07-29 10:40:47,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1438157687835_0001 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@4229c502, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2015-07-29 10:40:47,300 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1438157687835_0001_000001 to scheduler from user nadir in queue default
2015-07-29 10:40:47,303 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from SUBMITTED to SCHEDULED
2015-07-29 10:40:47,658 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2015-07-29 10:40:47,659 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0001	CONTAINERID=container_1438157687835_0001_01_000001
2015-07-29 10:40:47,659 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0001_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2015-07-29 10:40:47,659 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0001_000001 container=Container: [ContainerId: container_1438157687835_0001_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8>
2015-07-29 10:40:47,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 10:40:47,666 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 10:40:47,716 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0001_01_000001
2015-07-29 10:40:47,735 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 10:40:47,736 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1438157687835_0001_000001
2015-07-29 10:40:47,741 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1438157687835_0001 AttemptId: appattempt_1438157687835_0001_000001 MasterContainer: Container: [ContainerId: container_1438157687835_0001_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ]
2015-07-29 10:40:47,764 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from SCHEDULED to ALLOCATED_SAVING
2015-07-29 10:40:47,766 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from ALLOCATED_SAVING to ALLOCATED
2015-07-29 10:40:47,771 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1438157687835_0001_000001
2015-07-29 10:40:47,837 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1438157687835_0001_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0001_000001
2015-07-29 10:40:47,838 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1438157687835_0001_01_000001 : $JAVA_HOME/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2015-07-29 10:40:47,840 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1438157687835_0001_000001
2015-07-29 10:40:47,851 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1438157687835_0001_000001
2015-07-29 10:40:48,887 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1438157687835_0001_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0001_000001
2015-07-29 10:40:48,888 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from ALLOCATED to LAUNCHED
2015-07-29 10:40:49,547 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000001 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 10:41:06,881 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1438157687835_0001_000001 (auth:SIMPLE)
2015-07-29 10:41:06,903 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1438157687835_0001_000001
2015-07-29 10:41:06,909 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from LAUNCHED to RUNNING
2015-07-29 10:41:06,910 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0001 State change from ACCEPTED to RUNNING
2015-07-29 10:41:06,910 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1438157687835_0001	APPATTEMPTID=appattempt_1438157687835_0001_000001
2015-07-29 10:41:08,611 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000002 Container Transitioned from NEW to ALLOCATED
2015-07-29 10:41:08,611 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0001	CONTAINERID=container_1438157687835_0001_01_000002
2015-07-29 10:41:08,611 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0001_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 10:41:08,611 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0001_000001 container=Container: [ContainerId: container_1438157687835_0001_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 10:41:08,611 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 10:41:08,612 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 10:41:09,329 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0001_01_000002
2015-07-29 10:41:09,343 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 10:41:10,594 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0001
2015-07-29 10:41:10,621 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000002 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 10:41:24,970 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000002 Container Transitioned from RUNNING to COMPLETED
2015-07-29 10:41:24,970 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0001_01_000002 in state: COMPLETED event:FINISHED
2015-07-29 10:41:24,970 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0001	CONTAINERID=container_1438157687835_0001_01_000002
2015-07-29 10:41:24,970 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0001_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 10:41:24,971 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 10:41:24,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0001_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 10:41:24,972 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 10:41:24,973 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 10:41:24,973 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0001_000001 released container container_1438157687835_0001_01_000002 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 10:41:25,975 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000003 Container Transitioned from NEW to ALLOCATED
2015-07-29 10:41:25,976 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0001	CONTAINERID=container_1438157687835_0001_01_000003
2015-07-29 10:41:25,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0001_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 10:41:25,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0001_000001 container=Container: [ContainerId: container_1438157687835_0001_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 10:41:25,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 10:41:25,976 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 10:41:26,676 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 10:41:26,978 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000003 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 10:41:27,693 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0001
2015-07-29 10:41:41,608 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1438157687835_0001_000001 with final state: FINISHING, and exit status: -1000
2015-07-29 10:41:41,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from RUNNING to FINAL_SAVING
2015-07-29 10:41:41,612 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from FINAL_SAVING to FINISHING
2015-07-29 10:41:41,613 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1438157687835_0001 with final state: FINISHING
2015-07-29 10:41:41,616 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1438157687835_0001
2015-07-29 10:41:41,617 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0001 State change from RUNNING to FINAL_SAVING
2015-07-29 10:41:41,617 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0001 State change from FINAL_SAVING to FINISHING
2015-07-29 10:41:41,901 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000003 Container Transitioned from RUNNING to COMPLETED
2015-07-29 10:41:41,901 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0001_01_000003 in state: COMPLETED event:FINISHED
2015-07-29 10:41:41,901 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0001	CONTAINERID=container_1438157687835_0001_01_000003
2015-07-29 10:41:41,901 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0001_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 10:41:41,901 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 10:41:41,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0001_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 10:41:41,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 10:41:41,902 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 10:41:41,903 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0001_000001 released container container_1438157687835_0001_01_000003 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 10:41:42,625 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1438157687835_0001 unregistered successfully. 
2015-07-29 10:41:47,921 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0001_01_000001 Container Transitioned from RUNNING to COMPLETED
2015-07-29 10:41:47,921 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0001_01_000001 in state: COMPLETED event:FINISHED
2015-07-29 10:41:47,921 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0001	CONTAINERID=container_1438157687835_0001_01_000001
2015-07-29 10:41:47,921 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0001_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2015-07-29 10:41:47,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=nadir user-resources=<memory:0, vCores:0>
2015-07-29 10:41:47,922 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0001_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2015-07-29 10:41:47,923 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1438157687835_0001_000001
2015-07-29 10:41:47,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2015-07-29 10:41:47,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2015-07-29 10:41:47,925 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0001_000001 released container container_1438157687835_0001_01_000001 on node: host: morfus:60035 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2015-07-29 10:41:47,926 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1438157687835_0001_000001
2015-07-29 10:41:47,927 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0001_000001 State change from FINISHING to FINISHED
2015-07-29 10:41:47,930 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0001 State change from FINISHING to FINISHED
2015-07-29 10:41:47,930 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1438157687835_0001_000001 is done. finalState=FINISHED
2015-07-29 10:41:47,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1438157687835_0001 requests cleared
2015-07-29 10:41:47,931 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1438157687835_0001 user: nadir queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2015-07-29 10:41:47,932 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1438157687835_0001 user: nadir leaf-queue of parent: root #applications: 0
2015-07-29 10:41:47,935 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1438157687835_0001
2015-07-29 10:41:47,938 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1438157687835_0001,name=PigLatin:DefaultJobName,user=nadir,queue=default,state=FINISHED,trackingUrl=http://morfus:8088/proxy/application_1438157687835_0001/,appMasterHost=morfus,startTime=1438159247096,finishTime=1438159301613,finalStatus=SUCCEEDED,memorySeconds=156487,vcoreSeconds=91,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2015-07-29 10:41:47,939 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1438157687835_0001_000001
2015-07-29 10:41:48,996 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2015-07-29 10:49:36,315 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 2
2015-07-29 10:50:26,938 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 3
2015-07-29 10:50:28,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1438157687835_0003
2015-07-29 10:50:28,816 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0003 State change from NEW to NEW_SAVING
2015-07-29 10:50:28,816 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1438157687835_0003
2015-07-29 10:50:28,817 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0003 State change from NEW_SAVING to SUBMITTED
2015-07-29 10:50:28,817 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1438157687835_0003 user: nadir leaf-queue of parent: root #applications: 1
2015-07-29 10:50:28,817 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1438157687835_0003 from user: nadir, in queue: default
2015-07-29 10:50:28,818 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 3 submitted by user nadir
2015-07-29 10:50:28,818 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1438157687835_0003
2015-07-29 10:50:28,820 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0003 State change from SUBMITTED to ACCEPTED
2015-07-29 10:50:28,820 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1438157687835_0003_000001
2015-07-29 10:50:28,820 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from NEW to SUBMITTED
2015-07-29 10:50:28,824 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 10:50:28,824 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 10:50:28,824 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1438157687835_0003 from user: nadir activated in queue: default
2015-07-29 10:50:28,825 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1438157687835_0003 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@64585aae, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2015-07-29 10:50:28,825 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1438157687835_0003_000001 to scheduler from user nadir in queue default
2015-07-29 10:50:28,834 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from SUBMITTED to SCHEDULED
2015-07-29 10:50:29,389 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0003_01_000001 Container Transitioned from NEW to ALLOCATED
2015-07-29 10:50:29,389 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0003	CONTAINERID=container_1438157687835_0003_01_000001
2015-07-29 10:50:29,389 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0003_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2015-07-29 10:50:29,389 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0003_000001 container=Container: [ContainerId: container_1438157687835_0003_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8>
2015-07-29 10:50:29,391 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 10:50:29,391 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 10:50:29,398 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0003_01_000001
2015-07-29 10:50:29,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0003_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 10:50:29,401 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1438157687835_0003_000001
2015-07-29 10:50:29,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1438157687835_0003 AttemptId: appattempt_1438157687835_0003_000001 MasterContainer: Container: [ContainerId: container_1438157687835_0003_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ]
2015-07-29 10:50:29,401 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from SCHEDULED to ALLOCATED_SAVING
2015-07-29 10:50:29,402 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from ALLOCATED_SAVING to ALLOCATED
2015-07-29 10:50:29,402 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1438157687835_0003_000001
2015-07-29 10:50:29,405 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1438157687835_0003_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0003_000001
2015-07-29 10:50:29,405 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1438157687835_0003_01_000001 : $JAVA_HOME/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2015-07-29 10:50:29,406 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1438157687835_0003_000001
2015-07-29 10:50:29,406 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1438157687835_0003_000001
2015-07-29 10:50:29,434 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1438157687835_0003_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0003_000001
2015-07-29 10:50:29,434 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from ALLOCATED to LAUNCHED
2015-07-29 10:50:30,394 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0003_01_000001 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 10:50:45,275 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1438157687835_0003_000001 (auth:SIMPLE)
2015-07-29 10:50:45,283 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1438157687835_0003_000001
2015-07-29 10:50:45,283 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1438157687835_0003	APPATTEMPTID=appattempt_1438157687835_0003_000001
2015-07-29 10:50:45,283 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from LAUNCHED to RUNNING
2015-07-29 10:50:45,283 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0003 State change from ACCEPTED to RUNNING
2015-07-29 10:50:47,461 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0003_01_000002 Container Transitioned from NEW to ALLOCATED
2015-07-29 10:50:47,462 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0003	CONTAINERID=container_1438157687835_0003_01_000002
2015-07-29 10:50:47,462 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0003_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 10:50:47,462 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0003_000001 container=Container: [ContainerId: container_1438157687835_0003_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 10:50:47,463 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 10:50:47,463 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 10:50:47,704 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0003_01_000002
2015-07-29 10:50:47,709 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0003_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 10:50:48,468 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0003_01_000002 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 10:50:48,756 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0003
2015-07-29 10:51:01,749 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1438157687835_0003_000001 with final state: FINISHING, and exit status: -1000
2015-07-29 10:51:01,750 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from RUNNING to FINAL_SAVING
2015-07-29 10:51:01,750 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from FINAL_SAVING to FINISHING
2015-07-29 10:51:01,750 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1438157687835_0003 with final state: FINISHING
2015-07-29 10:51:01,750 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1438157687835_0003
2015-07-29 10:51:01,750 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0003 State change from RUNNING to FINAL_SAVING
2015-07-29 10:51:01,750 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0003 State change from FINAL_SAVING to FINISHING
2015-07-29 10:51:02,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0003_01_000002 Container Transitioned from RUNNING to COMPLETED
2015-07-29 10:51:02,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0003_01_000002 in state: COMPLETED event:FINISHED
2015-07-29 10:51:02,000 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0003	CONTAINERID=container_1438157687835_0003_01_000002
2015-07-29 10:51:02,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0003_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 10:51:02,000 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 10:51:02,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0003_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 10:51:02,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 10:51:02,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 10:51:02,002 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0003_000001 released container container_1438157687835_0003_01_000002 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 10:51:02,756 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1438157687835_0003 unregistered successfully. 
2015-07-29 10:51:08,019 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0003_01_000001 Container Transitioned from RUNNING to COMPLETED
2015-07-29 10:51:08,019 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0003_01_000001 in state: COMPLETED event:FINISHED
2015-07-29 10:51:08,019 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0003	CONTAINERID=container_1438157687835_0003_01_000001
2015-07-29 10:51:08,019 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0003_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2015-07-29 10:51:08,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=nadir user-resources=<memory:0, vCores:0>
2015-07-29 10:51:08,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0003_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2015-07-29 10:51:08,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2015-07-29 10:51:08,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2015-07-29 10:51:08,020 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0003_000001 released container container_1438157687835_0003_01_000001 on node: host: morfus:60035 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2015-07-29 10:51:08,022 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1438157687835_0003_000001
2015-07-29 10:51:08,022 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1438157687835_0003_000001
2015-07-29 10:51:08,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0003_000001 State change from FINISHING to FINISHED
2015-07-29 10:51:08,022 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0003 State change from FINISHING to FINISHED
2015-07-29 10:51:08,025 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1438157687835_0003
2015-07-29 10:51:08,026 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1438157687835_0003,name=PigLatin:DefaultJobName,user=nadir,queue=default,state=FINISHED,trackingUrl=http://morfus:8088/proxy/application_1438157687835_0003/,appMasterHost=morfus,startTime=1438159828815,finishTime=1438159861750,finalStatus=SUCCEEDED,memorySeconds=94000,vcoreSeconds=52,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2015-07-29 10:51:08,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1438157687835_0003_000001 is done. finalState=FINISHED
2015-07-29 10:51:08,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1438157687835_0003 requests cleared
2015-07-29 10:51:08,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1438157687835_0003 user: nadir queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2015-07-29 10:51:08,026 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1438157687835_0003 user: nadir leaf-queue of parent: root #applications: 0
2015-07-29 10:51:08,027 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1438157687835_0003_000001
2015-07-29 10:51:09,080 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2015-07-29 10:55:01,725 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 4
2015-07-29 10:55:03,588 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1438157687835_0004
2015-07-29 10:55:03,588 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0004 State change from NEW to NEW_SAVING
2015-07-29 10:55:03,588 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1438157687835_0004
2015-07-29 10:55:03,588 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0004 State change from NEW_SAVING to SUBMITTED
2015-07-29 10:55:03,588 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1438157687835_0004 user: nadir leaf-queue of parent: root #applications: 1
2015-07-29 10:55:03,589 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1438157687835_0004 from user: nadir, in queue: default
2015-07-29 10:55:03,589 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 4 submitted by user nadir
2015-07-29 10:55:03,590 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1438157687835_0004
2015-07-29 10:55:03,590 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0004 State change from SUBMITTED to ACCEPTED
2015-07-29 10:55:03,590 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1438157687835_0004_000001
2015-07-29 10:55:03,591 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from NEW to SUBMITTED
2015-07-29 10:55:03,591 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 10:55:03,591 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 10:55:03,591 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1438157687835_0004 from user: nadir activated in queue: default
2015-07-29 10:55:03,591 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1438157687835_0004 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@33bcf45b, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2015-07-29 10:55:03,591 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1438157687835_0004_000001 to scheduler from user nadir in queue default
2015-07-29 10:55:03,597 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from SUBMITTED to SCHEDULED
2015-07-29 10:55:03,675 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000001 Container Transitioned from NEW to ALLOCATED
2015-07-29 10:55:03,675 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0004	CONTAINERID=container_1438157687835_0004_01_000001
2015-07-29 10:55:03,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0004_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2015-07-29 10:55:03,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0004_000001 container=Container: [ContainerId: container_1438157687835_0004_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8>
2015-07-29 10:55:03,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 10:55:03,676 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 10:55:03,684 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0004_01_000001
2015-07-29 10:55:03,686 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 10:55:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1438157687835_0004_000001
2015-07-29 10:55:03,687 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1438157687835_0004 AttemptId: appattempt_1438157687835_0004_000001 MasterContainer: Container: [ContainerId: container_1438157687835_0004_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ]
2015-07-29 10:55:03,689 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from SCHEDULED to ALLOCATED_SAVING
2015-07-29 10:55:03,689 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from ALLOCATED_SAVING to ALLOCATED
2015-07-29 10:55:03,690 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1438157687835_0004_000001
2015-07-29 10:55:03,698 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1438157687835_0004_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0004_000001
2015-07-29 10:55:03,698 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1438157687835_0004_01_000001 : $JAVA_HOME/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2015-07-29 10:55:03,700 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1438157687835_0004_000001
2015-07-29 10:55:03,700 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1438157687835_0004_000001
2015-07-29 10:55:03,748 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1438157687835_0004_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0004_000001
2015-07-29 10:55:03,749 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from ALLOCATED to LAUNCHED
2015-07-29 10:55:04,677 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000001 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 10:55:17,925 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1438157687835_0004_000001 (auth:SIMPLE)
2015-07-29 10:55:17,932 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1438157687835_0004_000001
2015-07-29 10:55:17,932 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from LAUNCHED to RUNNING
2015-07-29 10:55:17,933 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0004 State change from ACCEPTED to RUNNING
2015-07-29 10:55:17,933 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1438157687835_0004	APPATTEMPTID=appattempt_1438157687835_0004_000001
2015-07-29 10:55:19,724 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000002 Container Transitioned from NEW to ALLOCATED
2015-07-29 10:55:19,725 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0004	CONTAINERID=container_1438157687835_0004_01_000002
2015-07-29 10:55:19,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0004_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 10:55:19,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0004_000001 container=Container: [ContainerId: container_1438157687835_0004_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 10:55:19,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 10:55:19,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 10:55:20,201 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0004_01_000002
2015-07-29 10:55:20,203 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 10:55:21,253 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0004
2015-07-29 10:55:21,728 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000002 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 10:55:36,588 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000002 Container Transitioned from RUNNING to COMPLETED
2015-07-29 10:55:36,588 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0004_01_000002 in state: COMPLETED event:FINISHED
2015-07-29 10:55:36,588 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0004	CONTAINERID=container_1438157687835_0004_01_000002
2015-07-29 10:55:36,588 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0004_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 10:55:36,588 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 10:55:36,589 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0004_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 10:55:36,590 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 10:55:36,590 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 10:55:36,590 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0004_000001 released container container_1438157687835_0004_01_000002 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 10:55:37,593 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000003 Container Transitioned from NEW to ALLOCATED
2015-07-29 10:55:37,593 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0004	CONTAINERID=container_1438157687835_0004_01_000003
2015-07-29 10:55:37,593 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0004_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 10:55:37,593 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0004_000001 container=Container: [ContainerId: container_1438157687835_0004_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 10:55:37,593 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 10:55:37,594 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 10:55:38,365 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 10:55:38,595 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000003 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 10:55:39,378 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0004
2015-07-29 10:55:52,107 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1438157687835_0004_000001 with final state: FINISHING, and exit status: -1000
2015-07-29 10:55:52,107 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from RUNNING to FINAL_SAVING
2015-07-29 10:55:52,107 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from FINAL_SAVING to FINISHING
2015-07-29 10:55:52,107 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1438157687835_0004 with final state: FINISHING
2015-07-29 10:55:52,107 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1438157687835_0004
2015-07-29 10:55:52,108 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0004 State change from RUNNING to FINAL_SAVING
2015-07-29 10:55:52,108 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0004 State change from FINAL_SAVING to FINISHING
2015-07-29 10:55:52,346 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000003 Container Transitioned from RUNNING to COMPLETED
2015-07-29 10:55:52,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0004_01_000003 in state: COMPLETED event:FINISHED
2015-07-29 10:55:52,347 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0004	CONTAINERID=container_1438157687835_0004_01_000003
2015-07-29 10:55:52,347 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0004_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 10:55:52,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 10:55:52,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0004_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 10:55:52,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 10:55:52,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 10:55:52,348 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0004_000001 released container container_1438157687835_0004_01_000003 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 10:55:53,113 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1438157687835_0004 unregistered successfully. 
2015-07-29 10:55:58,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0004_01_000001 Container Transitioned from RUNNING to COMPLETED
2015-07-29 10:55:58,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0004_01_000001 in state: COMPLETED event:FINISHED
2015-07-29 10:55:58,364 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0004	CONTAINERID=container_1438157687835_0004_01_000001
2015-07-29 10:55:58,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0004_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2015-07-29 10:55:58,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=nadir user-resources=<memory:0, vCores:0>
2015-07-29 10:55:58,364 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0004_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2015-07-29 10:55:58,365 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2015-07-29 10:55:58,365 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1438157687835_0004_000001
2015-07-29 10:55:58,366 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1438157687835_0004_000001
2015-07-29 10:55:58,366 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0004_000001 State change from FINISHING to FINISHED
2015-07-29 10:55:58,367 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0004 State change from FINISHING to FINISHED
2015-07-29 10:55:58,367 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1438157687835_0004
2015-07-29 10:55:58,368 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1438157687835_0004,name=PigLatin:DefaultJobName,user=nadir,queue=default,state=FINISHED,trackingUrl=http://morfus:8088/proxy/application_1438157687835_0004/,appMasterHost=morfus,startTime=1438160103587,finishTime=1438160152107,finalStatus=SUCCEEDED,memorySeconds=144379,vcoreSeconds=84,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2015-07-29 10:55:58,368 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2015-07-29 10:55:58,368 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0004_000001 released container container_1438157687835_0004_01_000001 on node: host: morfus:60035 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2015-07-29 10:55:58,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1438157687835_0004_000001 is done. finalState=FINISHED
2015-07-29 10:55:58,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1438157687835_0004 requests cleared
2015-07-29 10:55:58,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1438157687835_0004 user: nadir queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2015-07-29 10:55:58,369 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1438157687835_0004 user: nadir leaf-queue of parent: root #applications: 0
2015-07-29 10:55:58,369 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1438157687835_0004_000001
2015-07-29 10:55:59,411 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2015-07-29 11:17:39,305 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 5
2015-07-29 11:17:41,070 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1438157687835_0005
2015-07-29 11:17:41,071 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0005 State change from NEW to NEW_SAVING
2015-07-29 11:17:41,071 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1438157687835_0005
2015-07-29 11:17:41,071 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0005 State change from NEW_SAVING to SUBMITTED
2015-07-29 11:17:41,071 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1438157687835_0005 user: nadir leaf-queue of parent: root #applications: 1
2015-07-29 11:17:41,071 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1438157687835_0005 from user: nadir, in queue: default
2015-07-29 11:17:41,073 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0005 State change from SUBMITTED to ACCEPTED
2015-07-29 11:17:41,073 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1438157687835_0005_000001
2015-07-29 11:17:41,073 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from NEW to SUBMITTED
2015-07-29 11:17:41,073 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 5 submitted by user nadir
2015-07-29 11:17:41,073 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1438157687835_0005
2015-07-29 11:17:41,074 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 11:17:41,074 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 11:17:41,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1438157687835_0005 from user: nadir activated in queue: default
2015-07-29 11:17:41,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1438157687835_0005 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@3b5eaf92, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2015-07-29 11:17:41,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1438157687835_0005_000001 to scheduler from user nadir in queue default
2015-07-29 11:17:41,078 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from SUBMITTED to SCHEDULED
2015-07-29 11:17:41,344 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000001 Container Transitioned from NEW to ALLOCATED
2015-07-29 11:17:41,344 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0005	CONTAINERID=container_1438157687835_0005_01_000001
2015-07-29 11:17:41,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0005_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2015-07-29 11:17:41,344 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0005_000001 container=Container: [ContainerId: container_1438157687835_0005_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8>
2015-07-29 11:17:41,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 11:17:41,345 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 11:17:41,347 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0005_01_000001
2015-07-29 11:17:41,349 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 11:17:41,349 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1438157687835_0005_000001
2015-07-29 11:17:41,349 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1438157687835_0005 AttemptId: appattempt_1438157687835_0005_000001 MasterContainer: Container: [ContainerId: container_1438157687835_0005_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ]
2015-07-29 11:17:41,350 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from SCHEDULED to ALLOCATED_SAVING
2015-07-29 11:17:41,350 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from ALLOCATED_SAVING to ALLOCATED
2015-07-29 11:17:41,350 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1438157687835_0005_000001
2015-07-29 11:17:41,354 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1438157687835_0005_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0005_000001
2015-07-29 11:17:41,354 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1438157687835_0005_01_000001 : $JAVA_HOME/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2015-07-29 11:17:41,354 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1438157687835_0005_000001
2015-07-29 11:17:41,354 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1438157687835_0005_000001
2015-07-29 11:17:41,378 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1438157687835_0005_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0005_000001
2015-07-29 11:17:41,378 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from ALLOCATED to LAUNCHED
2015-07-29 11:17:42,348 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000001 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 11:17:53,580 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1438157687835_0005_000001 (auth:SIMPLE)
2015-07-29 11:17:53,592 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1438157687835_0005_000001
2015-07-29 11:17:53,593 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1438157687835_0005	APPATTEMPTID=appattempt_1438157687835_0005_000001
2015-07-29 11:17:53,593 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from LAUNCHED to RUNNING
2015-07-29 11:17:53,593 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0005 State change from ACCEPTED to RUNNING
2015-07-29 11:17:55,382 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000002 Container Transitioned from NEW to ALLOCATED
2015-07-29 11:17:55,382 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0005	CONTAINERID=container_1438157687835_0005_01_000002
2015-07-29 11:17:55,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0005_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 11:17:55,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0005_000001 container=Container: [ContainerId: container_1438157687835_0005_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 11:17:55,384 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 11:17:55,384 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 11:17:55,922 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0005_01_000002
2015-07-29 11:17:55,925 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 11:17:56,951 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0005
2015-07-29 11:17:57,387 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000002 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 11:19:19,051 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000002 Container Transitioned from RUNNING to COMPLETED
2015-07-29 11:19:19,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0005_01_000002 in state: COMPLETED event:FINISHED
2015-07-29 11:19:19,051 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0005	CONTAINERID=container_1438157687835_0005_01_000002
2015-07-29 11:19:19,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0005_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 11:19:19,051 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 11:19:19,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0005_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 11:19:19,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 11:19:19,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 11:19:19,052 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0005_000001 released container container_1438157687835_0005_01_000002 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 11:19:20,054 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000003 Container Transitioned from NEW to ALLOCATED
2015-07-29 11:19:20,054 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0005	CONTAINERID=container_1438157687835_0005_01_000003
2015-07-29 11:19:20,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0005_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 11:19:20,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0005_000001 container=Container: [ContainerId: container_1438157687835_0005_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 11:19:20,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 11:19:20,055 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 11:19:20,245 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 11:19:21,058 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000003 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 11:19:21,262 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0005
2015-07-29 11:19:48,305 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1438157687835_0005_000001 with final state: FINISHING, and exit status: -1000
2015-07-29 11:19:48,305 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from RUNNING to FINAL_SAVING
2015-07-29 11:19:48,305 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1438157687835_0005 with final state: FINISHING
2015-07-29 11:19:48,305 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0005 State change from RUNNING to FINAL_SAVING
2015-07-29 11:19:48,306 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1438157687835_0005
2015-07-29 11:19:48,306 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from FINAL_SAVING to FINISHING
2015-07-29 11:19:48,306 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0005 State change from FINAL_SAVING to FINISHING
2015-07-29 11:19:48,724 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000003 Container Transitioned from RUNNING to COMPLETED
2015-07-29 11:19:48,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0005_01_000003 in state: COMPLETED event:FINISHED
2015-07-29 11:19:48,724 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0005	CONTAINERID=container_1438157687835_0005_01_000003
2015-07-29 11:19:48,724 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0005_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 11:19:48,725 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 11:19:48,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0005_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 11:19:48,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 11:19:48,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 11:19:48,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0005_000001 released container container_1438157687835_0005_01_000003 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 11:19:49,312 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1438157687835_0005 unregistered successfully. 
2015-07-29 11:19:55,000 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0005_01_000001 Container Transitioned from RUNNING to COMPLETED
2015-07-29 11:19:55,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0005_01_000001 in state: COMPLETED event:FINISHED
2015-07-29 11:19:55,001 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0005	CONTAINERID=container_1438157687835_0005_01_000001
2015-07-29 11:19:55,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0005_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2015-07-29 11:19:55,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=nadir user-resources=<memory:0, vCores:0>
2015-07-29 11:19:55,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0005_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2015-07-29 11:19:55,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2015-07-29 11:19:55,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2015-07-29 11:19:55,001 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0005_000001 released container container_1438157687835_0005_01_000001 on node: host: morfus:60035 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2015-07-29 11:19:55,010 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1438157687835_0005_000001
2015-07-29 11:19:55,010 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1438157687835_0005_000001
2015-07-29 11:19:55,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0005_000001 State change from FINISHING to FINISHED
2015-07-29 11:19:55,011 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0005 State change from FINISHING to FINISHED
2015-07-29 11:19:55,011 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1438157687835_0005
2015-07-29 11:19:55,012 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1438157687835_0005,name=PigLatin:DefaultJobName,user=nadir,queue=default,state=FINISHED,trackingUrl=http://morfus:8088/proxy/application_1438157687835_0005/,appMasterHost=morfus,startTime=1438161461070,finishTime=1438161588305,finalStatus=SUCCEEDED,memorySeconds=388762,vcoreSeconds=244,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2015-07-29 11:19:55,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1438157687835_0005_000001 is done. finalState=FINISHED
2015-07-29 11:19:55,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1438157687835_0005 requests cleared
2015-07-29 11:19:55,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1438157687835_0005 user: nadir queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2015-07-29 11:19:55,013 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1438157687835_0005 user: nadir leaf-queue of parent: root #applications: 0
2015-07-29 11:19:55,018 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1438157687835_0005_000001
2015-07-29 11:19:56,154 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2015-07-29 11:54:14,765 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 6
2015-07-29 11:54:16,592 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1438157687835_0006
2015-07-29 11:54:16,593 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0006 State change from NEW to NEW_SAVING
2015-07-29 11:54:16,593 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1438157687835_0006
2015-07-29 11:54:16,593 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0006 State change from NEW_SAVING to SUBMITTED
2015-07-29 11:54:16,593 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1438157687835_0006 user: nadir leaf-queue of parent: root #applications: 1
2015-07-29 11:54:16,593 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1438157687835_0006 from user: nadir, in queue: default
2015-07-29 11:54:16,598 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 6 submitted by user nadir
2015-07-29 11:54:16,598 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1438157687835_0006
2015-07-29 11:54:16,599 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0006 State change from SUBMITTED to ACCEPTED
2015-07-29 11:54:16,599 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1438157687835_0006_000001
2015-07-29 11:54:16,599 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from NEW to SUBMITTED
2015-07-29 11:54:16,599 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 11:54:16,599 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 11:54:16,599 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1438157687835_0006 from user: nadir activated in queue: default
2015-07-29 11:54:16,599 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1438157687835_0006 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@35d58edd, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2015-07-29 11:54:16,600 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1438157687835_0006_000001 to scheduler from user nadir in queue default
2015-07-29 11:54:16,600 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from SUBMITTED to SCHEDULED
2015-07-29 11:54:17,495 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000001 Container Transitioned from NEW to ALLOCATED
2015-07-29 11:54:17,495 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0006	CONTAINERID=container_1438157687835_0006_01_000001
2015-07-29 11:54:17,495 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0006_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2015-07-29 11:54:17,495 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0006_000001 container=Container: [ContainerId: container_1438157687835_0006_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8>
2015-07-29 11:54:17,495 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 11:54:17,495 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 11:54:17,497 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0006_01_000001
2015-07-29 11:54:17,499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 11:54:17,499 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1438157687835_0006_000001
2015-07-29 11:54:17,500 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1438157687835_0006 AttemptId: appattempt_1438157687835_0006_000001 MasterContainer: Container: [ContainerId: container_1438157687835_0006_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ]
2015-07-29 11:54:17,500 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from SCHEDULED to ALLOCATED_SAVING
2015-07-29 11:54:17,500 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from ALLOCATED_SAVING to ALLOCATED
2015-07-29 11:54:17,501 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1438157687835_0006_000001
2015-07-29 11:54:17,504 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1438157687835_0006_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0006_000001
2015-07-29 11:54:17,504 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1438157687835_0006_01_000001 : $JAVA_HOME/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2015-07-29 11:54:17,504 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1438157687835_0006_000001
2015-07-29 11:54:17,504 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1438157687835_0006_000001
2015-07-29 11:54:17,549 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1438157687835_0006_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0006_000001
2015-07-29 11:54:17,549 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from ALLOCATED to LAUNCHED
2015-07-29 11:54:18,497 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000001 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 11:54:29,991 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1438157687835_0006_000001 (auth:SIMPLE)
2015-07-29 11:54:29,998 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1438157687835_0006_000001
2015-07-29 11:54:29,998 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1438157687835_0006	APPATTEMPTID=appattempt_1438157687835_0006_000001
2015-07-29 11:54:29,998 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from LAUNCHED to RUNNING
2015-07-29 11:54:29,999 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0006 State change from ACCEPTED to RUNNING
2015-07-29 11:54:31,533 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000002 Container Transitioned from NEW to ALLOCATED
2015-07-29 11:54:31,533 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0006	CONTAINERID=container_1438157687835_0006_01_000002
2015-07-29 11:54:31,533 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0006_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 11:54:31,533 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0006_000001 container=Container: [ContainerId: container_1438157687835_0006_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 11:54:31,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 11:54:31,534 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 11:54:32,362 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0006_01_000002
2015-07-29 11:54:32,364 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 11:54:33,539 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000002 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 11:54:33,540 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0006
2015-07-29 11:54:59,020 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000002 Container Transitioned from RUNNING to COMPLETED
2015-07-29 11:54:59,021 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0006_01_000002 in state: COMPLETED event:FINISHED
2015-07-29 11:54:59,021 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0006	CONTAINERID=container_1438157687835_0006_01_000002
2015-07-29 11:54:59,021 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0006_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 11:54:59,021 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 11:54:59,021 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0006_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 11:54:59,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 11:54:59,023 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 11:54:59,023 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0006_000001 released container container_1438157687835_0006_01_000002 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 11:55:00,021 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000003 Container Transitioned from NEW to ALLOCATED
2015-07-29 11:55:00,021 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0006	CONTAINERID=container_1438157687835_0006_01_000003
2015-07-29 11:55:00,021 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0006_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 11:55:00,021 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0006_000001 container=Container: [ContainerId: container_1438157687835_0006_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 11:55:00,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 11:55:00,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 11:55:00,651 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 11:55:01,026 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000003 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 11:55:01,660 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0006
2015-07-29 11:55:18,353 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1438157687835_0006_000001 with final state: FINISHING, and exit status: -1000
2015-07-29 11:55:18,353 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from RUNNING to FINAL_SAVING
2015-07-29 11:55:18,353 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from FINAL_SAVING to FINISHING
2015-07-29 11:55:18,353 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1438157687835_0006 with final state: FINISHING
2015-07-29 11:55:18,354 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1438157687835_0006
2015-07-29 11:55:18,354 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0006 State change from RUNNING to FINAL_SAVING
2015-07-29 11:55:18,354 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0006 State change from FINAL_SAVING to FINISHING
2015-07-29 11:55:18,418 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000003 Container Transitioned from RUNNING to COMPLETED
2015-07-29 11:55:18,419 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0006_01_000003 in state: COMPLETED event:FINISHED
2015-07-29 11:55:18,419 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0006	CONTAINERID=container_1438157687835_0006_01_000003
2015-07-29 11:55:18,419 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0006_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 11:55:18,419 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 11:55:18,419 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0006_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 11:55:18,419 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 11:55:18,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 11:55:18,420 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0006_000001 released container container_1438157687835_0006_01_000003 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 11:55:19,359 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1438157687835_0006 unregistered successfully. 
2015-07-29 11:55:25,435 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0006_01_000001 Container Transitioned from RUNNING to COMPLETED
2015-07-29 11:55:25,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0006_01_000001 in state: COMPLETED event:FINISHED
2015-07-29 11:55:25,435 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0006	CONTAINERID=container_1438157687835_0006_01_000001
2015-07-29 11:55:25,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0006_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2015-07-29 11:55:25,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=nadir user-resources=<memory:0, vCores:0>
2015-07-29 11:55:25,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0006_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2015-07-29 11:55:25,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2015-07-29 11:55:25,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2015-07-29 11:55:25,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0006_000001 released container container_1438157687835_0006_01_000001 on node: host: morfus:60035 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2015-07-29 11:55:25,437 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1438157687835_0006_000001
2015-07-29 11:55:25,437 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1438157687835_0006_000001
2015-07-29 11:55:25,437 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0006_000001 State change from FINISHING to FINISHED
2015-07-29 11:55:25,437 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0006 State change from FINISHING to FINISHED
2015-07-29 11:55:25,442 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1438157687835_0006
2015-07-29 11:55:25,443 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1438157687835_0006,name=PigLatin:DefaultJobName,user=nadir,queue=default,state=FINISHED,trackingUrl=http://morfus:8088/proxy/application_1438157687835_0006/,appMasterHost=morfus,startTime=1438163656592,finishTime=1438163718353,finalStatus=SUCCEEDED,memorySeconds=186129,vcoreSeconds=112,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2015-07-29 11:55:25,446 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1438157687835_0006_000001 is done. finalState=FINISHED
2015-07-29 11:55:25,446 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1438157687835_0006 requests cleared
2015-07-29 11:55:25,446 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1438157687835_0006 user: nadir queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2015-07-29 11:55:25,446 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1438157687835_0006 user: nadir leaf-queue of parent: root #applications: 0
2015-07-29 11:55:25,446 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1438157687835_0006_000001
2015-07-29 11:55:26,496 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2015-07-29 12:14:17,642 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 7
2015-07-29 12:14:19,318 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Storing application with id application_1438157687835_0007
2015-07-29 12:14:19,318 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0007 State change from NEW to NEW_SAVING
2015-07-29 12:14:19,318 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing info for app: application_1438157687835_0007
2015-07-29 12:14:19,319 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0007 State change from NEW_SAVING to SUBMITTED
2015-07-29 12:14:19,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application added - appId: application_1438157687835_0007 user: nadir leaf-queue of parent: root #applications: 1
2015-07-29 12:14:19,319 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Accepted application application_1438157687835_0007 from user: nadir, in queue: default
2015-07-29 12:14:19,320 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0007 State change from SUBMITTED to ACCEPTED
2015-07-29 12:14:19,320 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Application with id 7 submitted by user nadir
2015-07-29 12:14:19,320 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Submit Application Request	TARGET=ClientRMService	RESULT=SUCCESS	APPID=application_1438157687835_0007
2015-07-29 12:14:19,325 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Registering app attempt : appattempt_1438157687835_0007_000001
2015-07-29 12:14:19,325 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from NEW to SUBMITTED
2015-07-29 12:14:19,326 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 12:14:19,326 WARN org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: maximum-am-resource-percent is insufficient to start a single application in queue for user, it is likely set too low. skipping enforcement to allow at least one application to start
2015-07-29 12:14:19,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application application_1438157687835_0007 from user: nadir activated in queue: default
2015-07-29 12:14:19,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application added - appId: application_1438157687835_0007 user: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue$User@35e3094b, leaf-queue: default #user-pending-applications: 0 #user-active-applications: 1 #queue-pending-applications: 0 #queue-active-applications: 1
2015-07-29 12:14:19,326 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added Application Attempt appattempt_1438157687835_0007_000001 to scheduler from user nadir in queue default
2015-07-29 12:14:19,327 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from SUBMITTED to SCHEDULED
2015-07-29 12:14:20,038 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000001 Container Transitioned from NEW to ALLOCATED
2015-07-29 12:14:20,038 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0007	CONTAINERID=container_1438157687835_0007_01_000001
2015-07-29 12:14:20,038 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0007_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available after allocation
2015-07-29 12:14:20,038 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0007_000001 container=Container: [ContainerId: container_1438157687835_0007_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 clusterResource=<memory:8192, vCores:8>
2015-07-29 12:14:20,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 12:14:20,039 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 12:14:20,042 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0007_01_000001
2015-07-29 12:14:20,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000001 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 12:14:20,044 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Clear node set for appattempt_1438157687835_0007_000001
2015-07-29 12:14:20,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Storing attempt: AppId: application_1438157687835_0007 AttemptId: appattempt_1438157687835_0007_000001 MasterContainer: Container: [ContainerId: container_1438157687835_0007_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ]
2015-07-29 12:14:20,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from SCHEDULED to ALLOCATED_SAVING
2015-07-29 12:14:20,044 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from ALLOCATED_SAVING to ALLOCATED
2015-07-29 12:14:20,045 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Launching masterappattempt_1438157687835_0007_000001
2015-07-29 12:14:20,048 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Setting up container Container: [ContainerId: container_1438157687835_0007_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0007_000001
2015-07-29 12:14:20,048 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Command to launch container container_1438157687835_0007_01_000001 : $JAVA_HOME/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=<LOG_DIR> -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2015-07-29 12:14:20,048 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Create AMRMToken for ApplicationAttempt: appattempt_1438157687835_0007_000001
2015-07-29 12:14:20,048 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Creating password for appattempt_1438157687835_0007_000001
2015-07-29 12:14:20,070 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Done launching container Container: [ContainerId: container_1438157687835_0007_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] for AM appattempt_1438157687835_0007_000001
2015-07-29 12:14:20,071 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from ALLOCATED to LAUNCHED
2015-07-29 12:14:21,042 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000001 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 12:14:32,313 INFO SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for appattempt_1438157687835_0007_000001 (auth:SIMPLE)
2015-07-29 12:14:32,319 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AM registration appattempt_1438157687835_0007_000001
2015-07-29 12:14:32,320 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	IP=127.0.0.1	OPERATION=Register App Master	TARGET=ApplicationMasterService	RESULT=SUCCESS	APPID=application_1438157687835_0007	APPATTEMPTID=appattempt_1438157687835_0007_000001
2015-07-29 12:14:32,320 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from LAUNCHED to RUNNING
2015-07-29 12:14:32,320 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0007 State change from ACCEPTED to RUNNING
2015-07-29 12:14:34,074 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000002 Container Transitioned from NEW to ALLOCATED
2015-07-29 12:14:34,074 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0007	CONTAINERID=container_1438157687835_0007_01_000002
2015-07-29 12:14:34,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0007_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 12:14:34,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0007_000001 container=Container: [ContainerId: container_1438157687835_0007_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 12:14:34,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 12:14:34,074 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 12:14:34,668 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Sending NMToken for nodeId : morfus:60035 for container : container_1438157687835_0007_01_000002
2015-07-29 12:14:34,670 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000002 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 12:14:35,831 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0007
2015-07-29 12:14:36,080 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000002 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 12:14:57,722 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000002 Container Transitioned from RUNNING to COMPLETED
2015-07-29 12:14:57,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0007_01_000002 in state: COMPLETED event:FINISHED
2015-07-29 12:14:57,722 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0007	CONTAINERID=container_1438157687835_0007_01_000002
2015-07-29 12:14:57,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0007_01_000002 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 12:14:57,722 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 12:14:57,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0007_01_000002, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 12:14:57,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 12:14:57,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 12:14:57,723 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0007_000001 released container container_1438157687835_0007_01_000002 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 12:14:58,726 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000003 Container Transitioned from NEW to ALLOCATED
2015-07-29 12:14:58,726 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Allocated Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0007	CONTAINERID=container_1438157687835_0007_01_000003
2015-07-29 12:14:58,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Assigned container container_1438157687835_0007_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which has 2 containers, <memory:3072, vCores:2> used and <memory:5120, vCores:6> available after allocation
2015-07-29 12:14:58,726 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: assignedContainer application attempt=appattempt_1438157687835_0007_000001 container=Container: [ContainerId: container_1438157687835_0007_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: null, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 clusterResource=<memory:8192, vCores:8>
2015-07-29 12:14:58,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting assigned queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:3072, vCores:2>, usedCapacity=0.375, absoluteUsedCapacity=0.375, numApps=1, numContainers=2
2015-07-29 12:14:58,727 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: assignedContainer queue=root usedCapacity=0.375 absoluteUsedCapacity=0.375 used=<memory:3072, vCores:2> cluster=<memory:8192, vCores:8>
2015-07-29 12:14:58,918 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000003 Container Transitioned from ALLOCATED to ACQUIRED
2015-07-29 12:14:59,730 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000003 Container Transitioned from ACQUIRED to RUNNING
2015-07-29 12:14:59,936 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: checking for deactivate of application :application_1438157687835_0007
2015-07-29 12:15:14,077 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: Updating application attempt appattempt_1438157687835_0007_000001 with final state: FINISHING, and exit status: -1000
2015-07-29 12:15:14,078 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from RUNNING to FINAL_SAVING
2015-07-29 12:15:14,078 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Updating application application_1438157687835_0007 with final state: FINISHING
2015-07-29 12:15:14,078 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0007 State change from RUNNING to FINAL_SAVING
2015-07-29 12:15:14,078 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating info for app: application_1438157687835_0007
2015-07-29 12:15:14,078 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from FINAL_SAVING to FINISHING
2015-07-29 12:15:14,078 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0007 State change from FINAL_SAVING to FINISHING
2015-07-29 12:15:14,381 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000003 Container Transitioned from RUNNING to COMPLETED
2015-07-29 12:15:14,381 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0007_01_000003 in state: COMPLETED event:FINISHED
2015-07-29 12:15:14,382 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0007	CONTAINERID=container_1438157687835_0007_01_000003
2015-07-29 12:15:14,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0007_01_000003 of capacity <memory:1024, vCores:1> on host morfus:60035, which currently has 1 containers, <memory:2048, vCores:1> used and <memory:6144, vCores:7> available, release resources=true
2015-07-29 12:15:14,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:2048, vCores:1> numContainers=1 user=nadir user-resources=<memory:2048, vCores:1>
2015-07-29 12:15:14,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0007_01_000003, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:1024, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1 cluster=<memory:8192, vCores:8>
2015-07-29 12:15:14,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.25 absoluteUsedCapacity=0.25 used=<memory:2048, vCores:1> cluster=<memory:8192, vCores:8>
2015-07-29 12:15:14,382 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:2048, vCores:1>, usedCapacity=0.25, absoluteUsedCapacity=0.25, numApps=1, numContainers=1
2015-07-29 12:15:14,383 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0007_000001 released container container_1438157687835_0007_01_000003 on node: host: morfus:60035 #containers=1 available=<memory:6144, vCores:7> used=<memory:2048, vCores:1> with event: FINISHED
2015-07-29 12:15:15,084 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: application_1438157687835_0007 unregistered successfully. 
2015-07-29 12:15:20,397 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1438157687835_0007_01_000001 Container Transitioned from RUNNING to COMPLETED
2015-07-29 12:15:20,397 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp: Completed container: container_1438157687835_0007_01_000001 in state: COMPLETED event:FINISHED
2015-07-29 12:15:20,397 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=AM Released Container	TARGET=SchedulerApp	RESULT=SUCCESS	APPID=application_1438157687835_0007	CONTAINERID=container_1438157687835_0007_01_000001
2015-07-29 12:15:20,397 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode: Released container container_1438157687835_0007_01_000001 of capacity <memory:2048, vCores:1> on host morfus:60035, which currently has 0 containers, <memory:0, vCores:0> used and <memory:8192, vCores:8> available, release resources=true
2015-07-29 12:15:20,398 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1438157687835_0007_000001
2015-07-29 12:15:20,398 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: Application finished, removing password for appattempt_1438157687835_0007_000001
2015-07-29 12:15:20,398 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1438157687835_0007_000001 State change from FINISHING to FINISHED
2015-07-29 12:15:20,398 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1438157687835_0007 State change from FINISHING to FINISHED
2015-07-29 12:15:20,398 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: default used=<memory:0, vCores:0> numContainers=0 user=nadir user-resources=<memory:0, vCores:0>
2015-07-29 12:15:20,398 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: completedContainer container=Container: [ContainerId: container_1438157687835_0007_01_000001, NodeId: morfus:60035, NodeHttpAddress: morfus:8042, Resource: <memory:2048, vCores:1>, Priority: 0, Token: Token { kind: ContainerToken, service: 127.0.1.1:60035 }, ] queue=default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0 cluster=<memory:8192, vCores:8>
2015-07-29 12:15:20,398 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: completedContainer queue=root usedCapacity=0.0 absoluteUsedCapacity=0.0 used=<memory:0, vCores:0> cluster=<memory:8192, vCores:8>
2015-07-29 12:15:20,398 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Re-sorting completed queue: root.default stats: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=1, numContainers=0
2015-07-29 12:15:20,399 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application attempt appattempt_1438157687835_0007_000001 released container container_1438157687835_0007_01_000001 on node: host: morfus:60035 #containers=0 available=<memory:8192, vCores:8> used=<memory:0, vCores:0> with event: FINISHED
2015-07-29 12:15:20,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application Attempt appattempt_1438157687835_0007_000001 is done. finalState=FINISHED
2015-07-29 12:15:20,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1438157687835_0007 requests cleared
2015-07-29 12:15:20,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1438157687835_0007 user: nadir queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2015-07-29 12:15:20,401 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1438157687835_0007 user: nadir leaf-queue of parent: root #applications: 0
2015-07-29 12:15:20,400 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=nadir	OPERATION=Application Finished - Succeeded	TARGET=RMAppManager	RESULT=SUCCESS	APPID=application_1438157687835_0007
2015-07-29 12:15:20,415 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1438157687835_0007,name=PigLatin:DefaultJobName,user=nadir,queue=default,state=FINISHED,trackingUrl=http://morfus:8088/proxy/application_1438157687835_0007/,appMasterHost=morfus,startTime=1438164859318,finishTime=1438164914078,finalStatus=SUCCEEDED,memorySeconds=163861,vcoreSeconds=98,preemptedAMContainers=0,preemptedNonAMContainers=0,preemptedResources=<memory:0\, vCores:0>,applicationType=MAPREDUCE
2015-07-29 12:15:20,420 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1438157687835_0007_000001
2015-07-29 12:15:21,462 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Null container completed...
2015-07-29 14:54:57,371 INFO org.apache.hadoop.yarn.server.resourcemanager.ClientRMService: Allocated new applicationId: 8
2015-07-29 14:55:02,872 INFO org.apache.hadoop.ipc.Server: IPC Server handler 18 on 8032, call org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.getApplicationReport from 127.0.0.1:58828 Call#516 Retry#0
org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException: Application with id 'application_1438157687835_0008' doesn't exist in RM.
	at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getApplicationReport(ClientRMService.java:327)
	at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.getApplicationReport(ApplicationClientProtocolPBServiceImpl.java:175)
	at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:417)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2049)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2045)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2043)
2015-07-29 15:42:09,669 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: RECEIVED SIGNAL 15: SIGTERM
2015-07-29 15:42:09,705 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2015-07-29 15:42:09,712 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2015-07-29 15:42:09,713 INFO org.apache.hadoop.ipc.Server: Stopping server on 8032
2015-07-29 15:42:09,724 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8032
2015-07-29 15:42:09,725 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-29 15:42:09,726 INFO org.apache.hadoop.ipc.Server: Stopping server on 8033
2015-07-29 15:42:09,726 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8033
2015-07-29 15:42:09,727 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-29 15:42:09,727 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to standby state
2015-07-29 15:42:09,728 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ResourceManager metrics system...
2015-07-29 15:42:09,732 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system stopped.
2015-07-29 15:42:09,732 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system shutdown complete.
2015-07-29 15:42:09,732 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2015-07-29 15:42:09,735 WARN org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher: org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread interrupted. Returning.
2015-07-29 15:42:09,738 INFO org.apache.hadoop.ipc.Server: Stopping server on 8030
2015-07-29 15:42:09,748 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8030
2015-07-29 15:42:09,749 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-29 15:42:09,749 INFO org.apache.hadoop.ipc.Server: Stopping server on 8031
2015-07-29 15:42:09,758 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 8031
2015-07-29 15:42:09,759 INFO org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2015-07-29 15:42:09,760 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: NMLivelinessMonitor thread interrupted
2015-07-29 15:42:09,760 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Returning, interrupted : java.lang.InterruptedException
2015-07-29 15:42:09,760 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: AsyncDispatcher is draining to stop, igonring any new events.
2015-07-29 15:42:09,761 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2015-07-29 15:42:09,761 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: AMLivelinessMonitor thread interrupted
2015-07-29 15:42:09,762 INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.ContainerAllocationExpirer thread interrupted
2015-07-29 15:42:09,762 ERROR org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2015-07-29 15:42:09,763 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to standby state
2015-07-29 15:42:09,763 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ResourceManager at morfus/127.0.1.1
************************************************************/
2015-07-29 15:43:32,574 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ResourceManager
STARTUP_MSG:   host = morfus/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.7.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.42.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.1.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/contrib/capacity-scheduler/*.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/etc/hadoop/rm-config/log4j.properties
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 15ecc87ccf4a0228f35af08fc56de536e6ce657a; compiled by 'jenkins' on 2015-06-29T06:04Z
STARTUP_MSG:   java = 1.7.0_79
************************************************************/
2015-07-29 15:43:32,620 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: registered UNIX signal handlers for [TERM, HUP, INT]
2015-07-29 15:43:34,745 INFO org.apache.hadoop.conf.Configuration: found resource core-site.xml at file:/usr/local/hadoop/etc/hadoop/core-site.xml
2015-07-29 15:43:35,956 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-07-29 15:43:36,423 INFO org.apache.hadoop.security.Groups: clearing userToGroupsMap cache
2015-07-29 15:43:37,274 INFO org.apache.hadoop.conf.Configuration: found resource yarn-site.xml at file:/usr/local/hadoop/etc/hadoop/yarn-site.xml
2015-07-29 15:43:39,532 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMFatalEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMFatalEventDispatcher
2015-07-29 15:43:40,079 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: NMTokenKeyRollingInterval: 86400000ms and NMTokenKeyActivationDelay: 900000ms
2015-07-29 15:43:40,125 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: ContainerTokenKeyRollingInterval: 86400000ms and ContainerTokenKeyActivationDelay: 900000ms
2015-07-29 15:43:40,195 INFO org.apache.hadoop.yarn.server.resourcemanager.security.AMRMTokenSecretManager: AMRMTokenKeyRollingInterval: 86400000ms and AMRMTokenKeyActivationDelay: 900000 ms
2015-07-29 15:43:40,676 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreEventType for class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore$ForwardingEventHandler
2015-07-29 15:43:40,718 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.NodesListManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.NodesListManager
2015-07-29 15:43:40,735 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Using Scheduler: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
2015-07-29 15:43:40,957 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher
2015-07-29 15:43:40,973 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationEventDispatcher
2015-07-29 15:43:40,983 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$ApplicationAttemptEventDispatcher
2015-07-29 15:43:40,986 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeEventType for class org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$NodeEventDispatcher
2015-07-29 15:43:41,370 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2015-07-29 15:43:41,736 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2015-07-29 15:43:41,736 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ResourceManager metrics system started
2015-07-29 15:43:41,816 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.RMAppManagerEventType for class org.apache.hadoop.yarn.server.resourcemanager.RMAppManager
2015-07-29 15:43:41,880 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncherEventType for class org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher
2015-07-29 15:43:41,888 INFO org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo: Registered RMNMInfo MBean
2015-07-29 15:43:41,897 INFO org.apache.hadoop.yarn.security.YarnAuthorizationProvider: org.apache.hadoop.yarn.security.ConfiguredYarnAuthorizer is instiantiated.
2015-07-29 15:43:41,897 INFO org.apache.hadoop.yarn.server.resourcemanager.metrics.SystemMetricsPublisher: YARN system metrics publishing service is not enabled
2015-07-29 15:43:41,903 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2015-07-29 15:43:41,943 INFO org.apache.hadoop.conf.Configuration: found resource capacity-scheduler.xml at file:/usr/local/hadoop/etc/hadoop/capacity-scheduler.xml
2015-07-29 15:43:42,397 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root is undefined
2015-07-29 15:43:42,397 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root is undefined
2015-07-29 15:43:42,435 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: root, capacity=1.0, asboluteCapacity=1.0, maxCapacity=1.0, asboluteMaxCapacity=1.0, state=RUNNING, acls=ADMINISTER_QUEUE:*SUBMIT_APP:*, labels=*,
, reservationsContinueLooking=true
2015-07-29 15:43:42,436 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Initialized parent-queue root name=root, fullname=root
2015-07-29 15:43:42,552 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc mb per queue for root.default is undefined
2015-07-29 15:43:42,561 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration: max alloc vcore per queue for root.default is undefined
2015-07-29 15:43:42,564 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing default
capacity = 1.0 [= (float) configuredCapacity / 100 ]
asboluteCapacity = 1.0 [= parentAbsoluteCapacity * capacity ]
maxCapacity = 1.0 [= configuredMaxCapacity ]
absoluteMaxCapacity = 1.0 [= 1.0 maximumCapacity undefined, (parentAbsoluteMaxCapacity * maximumCapacity) / 100 otherwise ]
userLimit = 100 [= configuredUserLimit ]
userLimitFactor = 1.0 [= configuredUserLimitFactor ]
maxApplications = 10000 [= configuredMaximumSystemApplicationsPerQueue or (int)(configuredMaximumSystemApplications * absoluteCapacity)]
maxApplicationsPerUser = 10000 [= (int)(maxApplications * (userLimit / 100.0f) * userLimitFactor) ]
usedCapacity = 0.0 [= usedResourcesMemory / (clusterResourceMemory * absoluteCapacity)]
absoluteUsedCapacity = 0.0 [= usedResourcesMemory / clusterResourceMemory]
maxAMResourcePerQueuePercent = 0.1 [= configuredMaximumAMResourcePercent ]
minimumAllocationFactor = 0.875 [= (float)(maximumAllocationMemory - minimumAllocationMemory) / maximumAllocationMemory ]
maximumAllocation = <memory:8192, vCores:32> [= configuredMaxAllocation ]
numContainers = 0 [= currentNumContainers ]
state = RUNNING [= configuredState ]
acls = ADMINISTER_QUEUE:*SUBMIT_APP:* [= configuredAcls ]
nodeLocalityDelay = 40
labels=*,
nodeLocalityDelay = 40
reservationsContinueLooking = true
preemptionDisabled = true

2015-07-29 15:43:42,564 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: default: capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>, usedCapacity=0.0, absoluteUsedCapacity=0.0, numApps=0, numContainers=0
2015-07-29 15:43:42,565 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue: root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2015-07-29 15:43:42,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized root queue root: numChildQueue= 1, capacity=1.0, absoluteCapacity=1.0, usedResources=<memory:0, vCores:0>usedCapacity=0.0, numApps=0, numContainers=0
2015-07-29 15:43:42,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized queue mappings, override: false
2015-07-29 15:43:42,583 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Initialized CapacityScheduler with calculator=class org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator, minimumAllocation=<<memory:1024, vCores:1>>, maximumAllocation=<<memory:8192, vCores:32>>, asynchronousScheduling=false, asyncScheduleInterval=5ms
2015-07-29 15:43:42,648 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioning to active state
2015-07-29 15:43:42,756 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Updating AMRMToken
2015-07-29 15:43:42,762 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMContainerTokenSecretManager: Rolling master-key for container-tokens
2015-07-29 15:43:42,763 INFO org.apache.hadoop.yarn.server.resourcemanager.security.NMTokenSecretManagerInRM: Rolling master-key for nm-tokens
2015-07-29 15:43:42,771 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2015-07-29 15:43:42,772 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 1
2015-07-29 15:43:42,772 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2015-07-29 15:43:42,786 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2015-07-29 15:43:42,793 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2015-07-29 15:43:42,793 INFO org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager: storing master key with keyID 2
2015-07-29 15:43:42,804 INFO org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.yarn.nodelabels.event.NodeLabelsStoreEventType for class org.apache.hadoop.yarn.nodelabels.CommonNodeLabelsManager$ForwardingEventHandler
2015-07-29 15:43:42,813 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Storing RMDTMasterKey.
2015-07-29 15:43:43,061 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-07-29 15:43:43,182 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8031
2015-07-29 15:43:43,326 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceTrackerPB to the server
2015-07-29 15:43:43,343 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-29 15:43:43,347 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8031: starting
2015-07-29 15:43:43,759 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-07-29 15:43:43,802 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8030
2015-07-29 15:43:44,065 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationMasterProtocolPB to the server
2015-07-29 15:43:44,067 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-29 15:43:44,123 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8030: starting
2015-07-29 15:43:44,643 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-07-29 15:43:44,651 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8032
2015-07-29 15:43:44,676 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.api.ApplicationClientProtocolPB to the server
2015-07-29 15:43:44,679 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-29 15:43:44,716 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8032: starting
2015-07-29 15:43:44,875 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Transitioned to active state
2015-07-29 15:43:45,704 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2015-07-29 15:43:45,808 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2015-07-29 15:43:45,873 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.resourcemanager is not defined
2015-07-29 15:43:45,941 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2015-07-29 15:43:45,979 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context cluster
2015-07-29 15:43:45,980 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context logs
2015-07-29 15:43:45,980 INFO org.apache.hadoop.http.HttpServer2: Added filter RMAuthenticationFilter (class=org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilter) to context static
2015-07-29 15:43:45,981 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context cluster
2015-07-29 15:43:45,981 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2015-07-29 15:43:45,981 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2015-07-29 15:43:46,012 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /cluster/*
2015-07-29 15:43:46,012 INFO org.apache.hadoop.http.HttpServer2: adding path spec: /ws/*
2015-07-29 15:43:46,094 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 8088
2015-07-29 15:43:46,095 INFO org.mortbay.log: jetty-6.1.26
2015-07-29 15:43:46,248 INFO org.mortbay.log: Extract jar:file:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.7.1.jar!/webapps/cluster to /tmp/Jetty_0_0_0_0_8088_cluster____u0rgz3/webapp
2015-07-29 15:43:47,433 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2015-07-29 15:43:47,445 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2015-07-29 15:43:47,456 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2015-07-29 15:43:47,519 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:8088
2015-07-29 15:43:47,519 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /cluster started at 8088
2015-07-29 15:43:49,694 INFO org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
2015-07-29 15:43:49,892 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2015-07-29 15:43:49,893 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8033
2015-07-29 15:43:49,906 INFO org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB to the server
2015-07-29 15:43:49,915 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2015-07-29 15:43:49,920 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8033: starting
2015-07-29 15:43:51,131 INFO org.apache.hadoop.yarn.util.RackResolver: Resolved morfus to /default-rack
2015-07-29 15:43:51,140 INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: morfus:49307 Node Transitioned from NEW to RUNNING
2015-07-29 15:43:51,140 INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: NodeManager from node morfus(cmPort: 49307 httpPort: 8042) registered with capability: <memory:8192, vCores:8>, assigned nodeId morfus:49307
2015-07-29 15:43:51,170 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Added node morfus:49307 clusterResource: <memory:8192, vCores:8>
2015-07-29 15:53:41,943 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler: Release request cache is cleaned up
